{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/timeseries-forecasting-1/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Yeti in Ness"}},"markdownRemark":{"id":"db93e5af-acf1-5a6c-8aca-88ce964cd72a","excerpt":"이 글은 기본적으로 고려대학교 산업공학과1 김성범 교수님이 유튜브에 공개한 202…","html":"<p>이 글은 기본적으로 고려대학교 산업공학과<sup><a href=\"#footnote_1\">1</a></sup> 김성범 교수님이 유튜브에 공개한 2020년도 예측모델 강의를 들으면서 정리한 노트를, 나의 언어로 바꿔 쓰면서 흐름을 이해하기 위해 적은 것이다.</p>\n<p>내 경험 상 수업에서 배운 개별적인 방법론을 실무에 적용하려고 하면 결국 다시 찾아봐야 한다. 수식은 까먹는다. 중요한 건 어떤 흐름에서 각 방법론이 나왔는지(A 모델은 무슨 목적으로 만들어졌는데 어떤 한계가 있어 그것을 보완한 B 모델이 나왔고 하는 식)에 대해 머릿속에 목차를 만들어서, 필요한 키워드로 다시 서치할 수 있게 만드는 것이다.</p>\n<h2>시계열 데이터의 구성요소와 오차 측정 방식</h2>\n<h3>1. 시계열 데이터를 구성하는 것은?</h3>\n<ul>\n<li>Trend: 추세변동</li>\n<li>Cycle: 순환, 주기변동</li>\n<li>(Cycle의 하위 범주로서의) Seasonal Variation</li>\n<li>Random Fluctuation\n<ul>\n<li>White Noise: 우연변동 중, 평균이 0이고 분산이 일정한 것</li>\n</ul>\n</li>\n</ul>\n<p>Q. 단순한 raw 시계열 데이터를 받았을 때 위와 같은 구성요소들로 분해할 수는 없을까?\n<br> A. 위와 같은 구성요소로 분리해주는 것을 <code class=\"language-text\">Time Series Decomposition</code> 이라 부르며, R, Python에서 관련 라이브러리가 함수로 제공한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> statsmodels<span class=\"token punctuation\">.</span>tsa<span class=\"token punctuation\">.</span>seasonal <span class=\"token keyword\">import</span> seasonal_decompose\n\ndf <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'AirPassengers.csv'</span><span class=\"token punctuation\">)</span>\nresult <span class=\"token operator\">=</span> seasonal_decompose<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'Passengers'</span><span class=\"token punctuation\">,</span>   model<span class=\"token operator\">=</span><span class=\"token string\">'multiplicable'</span><span class=\"token punctuation\">,</span> period<span class=\"token operator\">=</span><span class=\"token number\">12</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>2. 시계열 예측 모델을 만들었다 치고, 내가 만든 모델에 대한 평가는 어떻게 할까?</h3>\n<ol>\n<li>MAD(Mean Absolute Deviation)</li>\n</ol>\n<p>$$MAD = \\frac{\\Sigma_{t=1}^n|e_t|}{n} = \\frac{\\Sigma_{t=1}^n|y_t-\\hat{y_t}|}{n}$$\n2. MSE(Mean Squared Error)\n$$MSE = \\frac{\\Sigma_{t=1}^n(e_t)^2}{n} = \\frac{\\Sigma_{t=1}^n(y_t-\\hat{y_t})^2}{n}$$</p>\n<ul>\n<li>오차를 ‘제곱’하는 부분 때문에 MAD에 비해 한두개라도 큰 오차가 존재하면 패널티가 커짐.</li>\n</ul>\n<ol start=\"3\">\n<li>MAPE(Mean Absolute Percentage Error)</li>\n</ol>\n<p>$$MSE = \\frac{\\Sigma_{t=1}^n(e_t)^2}{n} = \\frac{\\Sigma_{t=1}^n(y_t-\\hat{y_t})^2}{n}$$</p>\n<ul>\n<li>분모에 있는 실제값(y) 0이면 정의되지 않음</li>\n<li>분모에 있는 실제값이 매우 작으면 MAPE값이 매우 커짐</li>\n<li>오차의 절대값이 같아도, 분모가 실제값 기준이기 때문에 MAPE값이 매우 다르게 나올 수 있다.</li>\n</ul>\n<br>\n<h2>시계열 회귀모델과 자기회귀</h2>\n<h3>3. 예측? 회귀모델로 하면 되는 거 아닌가?</h3>\n<p>자, 뭔가를 통계적 모델로 예측한다고 했을 때 가장 먼저 떠오르는 것이 뭘까? 시간의 흐름에 따라(X) 변하는 값(Y)… 이 관계를 구하면 아직 나타나지 않은 X에 대해서도 Y를 예측할 수 있지 않을까?</p>\n<p>그래, 회귀가 먼저 떠오른다. 이미 결과를 알고 있는 데이터로 모델을 학습시켜서 이후에 아직 결과를 모르는 데이터에 적용하는 지도 학습<sup><a href=\"#footnote_2\">1</a></sup>에 회귀를 사용하는 것이다. 시간과 예측하려는 값의 관계를 회귀모델로 간단하게 나타내면 다음과 같다.</p>\n<p>$$y_t = TR_t + \\varepsilon_t$$</p>\n<h3>4.하지만 시계열 데이터로는 선형회귀 모델을 만들 수 없대…</h3>\n<p>그런데, 시계열 데이터로 선형회귀모델을 만들기 힘든 이유가 있다. 단순선형회귀 모델에는 여러 가정이 깔려있는데(그리고 각 가정이 위배되는 경우에 대해 사용할 수 있는 파생모델이 있다), 그 중 시계열 데이터는 <em>오차항이 서로 독립이어야 한다</em> 는 가정에 위배될 가능성이 크기 때문이다. 왜냐하면 시계열 회귀모델의 x변수인 시간의 특성상 t시점의 데이터는 t-1시점의 데이터에 영향을 받았을 가능성이 크기 때문이다. 8월 14일의 기온은 8월 13의 기온과 비슷할 확률이 높고 2008년 5월의 애플 주식 가격은 2022년 5월의 주가보다는 같은 해 6월과 훨씬 비슷하듯이 말이다.</p>\n<h3>5.자기 회귀 - 시계열 데이터의 끈끈한 자기애</h3>\n<p>아 그래, 시계열 데이터는 이전 시점의 데이터와 독립적이지 못하고 끈끈한 관계가 있단 말이지..? 그럼 이 관계를 뭐라고 지칭할까.\n<code class=\"language-text\">자기회귀(Autocorrelation)</code>. Auto(자기 자신)에 대해 Correlation(상관)이 있는 특성. 이 오묘한 특성은 앞으로도 여러 시계열 모델에서 등장하는 개념이니 잘 기억해두자.</p>\n<h4>그런데 자기 회귀에도 여러 종류가 있단다.</h4>\n<ul>\n<li>Positive Autocorrelation: 흔히 생각하는, 비슷한 오차항이 연달아나오는 경우. 시간에 따른 residual plot을 그려보면 연달아서 +가 나오거나 연달아서 -가 나오는 형태</li>\n<li>Negative Autocorrelation: postiive error term과 negative error term이 번갈아 나오는 형태. 근데 상식적으로 오차항이 저렇게 나오는 데이터가 잘 떠오르지는 않는다(아는 분 제보 부탁). 검색해봐도 개념 설명은 많은데 실제 데이터에서 오차항이 저렇게 time step마다 크게 차이나는 경우는 잘 본 적이 없다.</li>\n</ul>\n<h4>그럼, Autocorrelation의 존재는 어떻게 확인할까?</h4>\n<ul>\n<li>위처럼 residual plot을 그려서 눈으로 확인할 수도 있지만, 늘 그렇듯 현실의 데이터는 교과서의 예제처럼 뚜렷하게 나타나지 않는다</li>\n<li><code class=\"language-text\">Durbin-Watson Test</code>를 통해 수치적으로 자기회귀가 있는지 검증한다.</li>\n</ul>\n<h4>Durbin-Watson Test란?</h4>\n<ul>\n<li>1st-order(즉 원래의 데이터와, 한 시점 미룬 해당 데이터) 간에 positive autocorrelation이 있는지 확인하는 테스트.</li>\n<li>두 시점 이상 미룬 건 Durbin-Watson로는 확인 불가. higher-order autocorrelation에 대해서는 Breusch-Godfrey-test 등의 대안이 있다.</li>\n<li>반대로 Durbin-Watson Test로 negative autocorrelation도 구할 수 있는데, 이건 생략.</li>\n</ul>\n<p>$$d = \\sum_{i=2}^{n} (e_i - e_{i-1})^2/\\sum_{i=1}^ne_i^2 \\newline where; e_i = y_i - \\hat{y_i}$$</p>\n<ul>\n<li>검정통계량 d값이 lowerbound threshold값보다 작으면 자기 상관성이 있음</li>\n<li>검정통계량 d값이 upper threshold값보다 크면 자기 상관성이 없음</li>\n<li>검정통계량 d값이 lower bound &#x3C; d &#x3C; upper bound이면 자기 상관성이 존재</li>\n</ul>\n<p>참고로 이 lower bound($d_L$), upper bound($d_U$)는 데이터의 개수(sample size), X 변수 개수, sigificance level에 따라 구하는 표가 따로 있으니 참고.</p>\n<p>참고로 이걸 직접 매번 표 보고 귀무가설(Autocorrelation이 없다)가설과 대립가설 세워서 가설검정을 직접 하는 것은 매우 귀찮은 일이기 때문에 이미 웬만한 회귀 모델링 컴퓨터 패키지에서는 알아서 다 계산해주고, <code class=\"language-text\">d-statistics</code> 라는 이름으로 출력해준다. 압도적 감사.</p>\n<hr>\n<h3>참고 자료</h3>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=5QnR4L3KGz4&#x26;list=PLpIPLT0Pf7IqSuMx237SHRdLd5ZA4AQwd&#x26;index=7\">고려대학교 김성범 교수님 예측 모델 강의</a></li>\n</ul>\n<h3>주석</h3>\n<ul>\n<li><a name=\"footnote_1\">1</a> <a href=\"http://dmqa.korea.ac.kr/\">http://dmqa.korea.ac.kr/</a></li>\n<li><a name=\"footnote_2\">2</a> 데이터 과학을 위한 통계(2판), 피터 브루스 외, 4장 회귀와 예측, 165페이지</li>\n</ul>","frontmatter":{"title":"통계적 시계열 예측 모델의 흐름 - PART1","date":"January 31, 2022","description":"시계열 예측에 대한 전통적인 통계적 접근 방식들에 대해 각각이 가진 특성과 파생된 이유에 대해 간략하게 정리해보자."}},"previous":{"fields":{"slug":"/first-blog-post/"},"frontmatter":{"title":"2934번째 발견된 블로그"}},"next":null},"pageContext":{"id":"db93e5af-acf1-5a6c-8aca-88ce964cd72a","previousPostId":"25f89f20-3691-5a2f-9f66-f614ba878ef0","nextPostId":null}},
    "staticQueryHashes": ["2841359383","3257411868"]}